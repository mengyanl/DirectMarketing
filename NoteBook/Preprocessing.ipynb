{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79076498",
   "metadata": {},
   "source": [
    "# # SpringBoard Capstone2: Direct Marketing\n",
    "## Unit16: Pre-processing and Training Data Development \n",
    "> Data from Kaggle.com: https://www.kaggle.com/c/bankdirectmarketing/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2c01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e6db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "# check version number\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29da71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d35032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age           job   marital            education  default housing  \\\n",
      "RecordID                                                                      \n",
      "13783      49        admin.  divorced  professional.course       no     yes   \n",
      "23986      52      services   married          high.school  unknown     yes   \n",
      "20663      46   blue-collar  divorced             basic.9y       no      no   \n",
      "13958      26  entrepreneur    single          high.school      yes     yes   \n",
      "28184      47        admin.    single    university.degree       no      no   \n",
      "\n",
      "         loan   contact month day_of_week  ...  campaign  pdays  previous  \\\n",
      "RecordID                                   ...                              \n",
      "13783     yes  cellular   aug         mon  ...         1    115         2   \n",
      "23986      no  cellular   may         mon  ...         1    402         2   \n",
      "20663      no  cellular   apr         wed  ...         1    999         1   \n",
      "13958     yes  cellular   aug         fri  ...        28    999         0   \n",
      "28184      no  cellular   nov         tue  ...         1    252         4   \n",
      "\n",
      "             poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "RecordID                                                                       \n",
      "13783         failure          1.4       92.479703     -35.498996   0.705058   \n",
      "23986     nonexistent         -1.8       93.439161     -39.331320   4.245479   \n",
      "20663         failure         -1.8       93.075000     -47.100000   1.445000   \n",
      "13958     nonexistent          1.4       93.444000     -36.100000   4.967000   \n",
      "28184         success         -3.4       94.352376     -33.073620   1.208702   \n",
      "\n",
      "          nr.employed  subscribe  \n",
      "RecordID                          \n",
      "13783     4990.198481         no  \n",
      "23986     5144.563621        yes  \n",
      "20663     5099.100000         no  \n",
      "13958     5228.100000        yes  \n",
      "28184     5025.420036         no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "market_pre = pd.read_csv('Market_explored.csv', index_col = 0)\n",
    "print(market_pre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541de751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
       "RecordID                                                                     \n",
       "13783                   0                 0              0               0   \n",
       "23986                   0                 0              0               0   \n",
       "20663                   1                 0              0               0   \n",
       "13958                   0                 1              0               0   \n",
       "28184                   0                 0              0               0   \n",
       "\n",
       "          job_retired  job_self-employed  job_services  job_student  \\\n",
       "RecordID                                                              \n",
       "13783               0                  0             0            0   \n",
       "23986               0                  0             1            0   \n",
       "20663               0                  0             0            0   \n",
       "13958               0                  0             0            0   \n",
       "28184               0                  0             0            0   \n",
       "\n",
       "          job_technician  job_unemployed  ...  month_may  month_nov  \\\n",
       "RecordID                                  ...                         \n",
       "13783                  0               0  ...          0          0   \n",
       "23986                  0               0  ...          1          0   \n",
       "20663                  0               0  ...          0          0   \n",
       "13958                  0               0  ...          0          0   \n",
       "28184                  0               0  ...          0          1   \n",
       "\n",
       "          month_oct  month_sep  day_of_week_mon  day_of_week_thu  \\\n",
       "RecordID                                                           \n",
       "13783             0          0                1                0   \n",
       "23986             0          0                1                0   \n",
       "20663             0          0                0                0   \n",
       "13958             0          0                0                0   \n",
       "28184             0          0                0                0   \n",
       "\n",
       "          day_of_week_tue  day_of_week_wed  poutcome_nonexistent  \\\n",
       "RecordID                                                           \n",
       "13783                   0                0                     0   \n",
       "23986                   0                0                     1   \n",
       "20663                   0                1                     0   \n",
       "13958                   0                0                     1   \n",
       "28184                   1                0                     0   \n",
       "\n",
       "          poutcome_success  \n",
       "RecordID                    \n",
       "13783                    0  \n",
       "23986                    0  \n",
       "20663                    0  \n",
       "13958                    0  \n",
       "28184                    1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = market_pre[['job', 'marital', 'education', 'default', 'housing', \\\n",
    " 'loan', 'contact', 'month', 'day_of_week', 'poutcome']]\n",
    "market_cat = pd.get_dummies(cat,drop_first = True)\n",
    "print(market_cat.shape)\n",
    "market_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afc4e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>4457</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>92.479703</td>\n",
       "      <td>-35.498996</td>\n",
       "      <td>0.705058</td>\n",
       "      <td>4990.198481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4797</td>\n",
       "      <td>1</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.439161</td>\n",
       "      <td>-39.331320</td>\n",
       "      <td>4.245479</td>\n",
       "      <td>5144.563621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-47.100000</td>\n",
       "      <td>1.445000</td>\n",
       "      <td>5099.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>376</td>\n",
       "      <td>28</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444000</td>\n",
       "      <td>-36.100000</td>\n",
       "      <td>4.967000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>3033</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>94.352376</td>\n",
       "      <td>-33.073620</td>\n",
       "      <td>1.208702</td>\n",
       "      <td>5025.420036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
       "RecordID                                                                     \n",
       "13783                   0                 0              0               0   \n",
       "23986                   0                 0              0               0   \n",
       "20663                   1                 0              0               0   \n",
       "13958                   0                 1              0               0   \n",
       "28184                   0                 0              0               0   \n",
       "\n",
       "          job_retired  job_self-employed  job_services  job_student  \\\n",
       "RecordID                                                              \n",
       "13783               0                  0             0            0   \n",
       "23986               0                  0             1            0   \n",
       "20663               0                  0             0            0   \n",
       "13958               0                  0             0            0   \n",
       "28184               0                  0             0            0   \n",
       "\n",
       "          job_technician  job_unemployed  ...  age  duration  campaign  pdays  \\\n",
       "RecordID                                  ...                                   \n",
       "13783                  0               0  ...   49      4457         1    115   \n",
       "23986                  0               0  ...   52      4797         1    402   \n",
       "20663                  0               0  ...   46       169         1    999   \n",
       "13958                  0               0  ...   26       376        28    999   \n",
       "28184                  0               0  ...   47      3033         1    252   \n",
       "\n",
       "          previous  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "RecordID                                                                     \n",
       "13783            2           1.4       92.479703     -35.498996   0.705058   \n",
       "23986            2          -1.8       93.439161     -39.331320   4.245479   \n",
       "20663            1          -1.8       93.075000     -47.100000   1.445000   \n",
       "13958            0           1.4       93.444000     -36.100000   4.967000   \n",
       "28184            4          -3.4       94.352376     -33.073620   1.208702   \n",
       "\n",
       "          nr.employed  \n",
       "RecordID               \n",
       "13783     4990.198481  \n",
       "23986     5144.563621  \n",
       "20663     5099.100000  \n",
       "13958     5228.100000  \n",
       "28184     5025.420036  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', \\\n",
    "             'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "market_num = market_pre[num]\n",
    "market_all = market_cat.join(market_num)\n",
    "market_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e53e0e",
   "metadata": {},
   "source": [
    "#### SMOTE\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdbc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logreg_model(X,y,c):\n",
    "    over = SMOTE(sampling_strategy=c)\n",
    "    X, y = over.fit_resample(X, y)\n",
    "    counter = Counter(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled=scaler.transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return [c, counter, f1_score(y_test, y_pred, average=None), f1_score(y_test, y_pred, average='macro')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3454ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, Counter({'no': 19548, 'yes': 5864}), array([0.87820513, 0.41102181]), 0.6446134711060084]\n",
      "[0.4, Counter({'no': 19548, 'yes': 7819}), array([0.86116653, 0.51256696]), 0.686866742419308]\n",
      "[0.5, Counter({'no': 19548, 'yes': 9774}), array([0.84050514, 0.57079924]), 0.7056521949016891]\n",
      "[0.6, Counter({'no': 19548, 'yes': 11728}), array([0.78739957, 0.64311711]), 0.7152583359633451]\n",
      "[0.7, Counter({'no': 19548, 'yes': 13683}), array([0.75806036, 0.66137184]), 0.7097160985502766]\n",
      "[0.8, Counter({'no': 19548, 'yes': 15638}), array([0.77895001, 0.71213608]), 0.7455430468424722]\n",
      "[0.9, Counter({'no': 19548, 'yes': 17593}), array([0.83453419, 0.81157334]), 0.8230537669532378]\n",
      "[1, Counter({'no': 19548, 'yes': 19548}), array([0.70713162, 0.72116825]), 0.7141499339873252]\n"
     ]
    }
   ],
   "source": [
    "for c in [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    print(fit_logreg_model(market_all,market_pre['subscribe'],c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305d733",
   "metadata": {},
   "source": [
    "### use sampling_strategy = 0.9 for SMOTE( ) over sampling for category 1, f1_macro = 0.746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ce8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build scaler based on training data and apply it to test data to then also scale the test data\n",
    "## This is not the best of all\n",
    "# import sklearn.preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_scaled=scaler.transform(X_train)\n",
    "# X_test_scaled=scaler.transform(X_test)\n",
    "# X_train_scaled[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1e5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use MinMaxScaler() after test: this is the best\n",
    "# scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "# X_train_scaled=scaler.transform(X_train)\n",
    "# X_test_scaled=scaler.transform(X_test)\n",
    "# X_train_scaled[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "566183de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale only numerical columns\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train[num])\n",
    "# X_train_scaled=scaler.transform(X_train[num])\n",
    "# X_test_scaled=scaler.transform(X_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc20c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the logistic regression classifier: logreg\n",
    "# logreg = LogisticRegression()\n",
    "# # Fit it to the training data\n",
    "# logreg.fit(X_train,y_train)\n",
    "# y_pred = logreg.predict(X_test)\n",
    "# # Compute and print the confusion matrix and classification report\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf23e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = market_all\n",
    "y = market_pre['subscribe']\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.9)\n",
    "X, y = over.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c55d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 0.00018873918221350977, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Average f1_macro: 0.7529023684821268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-4, 4, 30)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5, scoring='f1_macro')\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Average f1_macro: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "547bb071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_no_average:  [0.93073542 0.        ]\n",
      "f1_macro:  0.4653677082095759\n"
     ]
    }
   ],
   "source": [
    "X = market_all\n",
    "y = market_pre['subscribe']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "X_train_scaled[0:1]\n",
    "\n",
    "RF = RandomForestClassifier(max_depth=3, random_state = 1)\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "print('f1_no_average: ', f1_score(y_test, y_pred, average=None))\n",
    "print('f1_macro: ', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a180540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_RF_model(X,y,c):\n",
    "    over = SMOTE(sampling_strategy=c)\n",
    "    X, y = over.fit_resample(X, y)\n",
    "    counter = Counter(y)\n",
    "    print('c: ', c, ', Counter: ', counter)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled=scaler.transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "    X_train_scaled[0:1]\n",
    "\n",
    "    RF = RandomForestClassifier(max_depth=3, random_state = 1)\n",
    "    RF.fit(X_train,y_train)\n",
    "    y_pred = RF.predict(X_test)\n",
    " \n",
    "    print('f1_none: ', f1_score(y_test, y_pred, average=None))\n",
    "    print('f1_macro: ', f1_score(y_test, y_pred, average='macro')) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "387a7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  0.3 , Counter:  Counter({'no': 19548, 'yes': 5864})\n",
      "f1_none:  [0.87660437 0.14641745]\n",
      "f1_macro:  0.5115109069341823\n",
      "None\n",
      "c:  0.4 , Counter:  Counter({'no': 19548, 'yes': 7819})\n",
      "f1_none:  [0.8620462  0.32508073]\n",
      "f1_macro:  0.593563468295161\n",
      "None\n",
      "c:  0.5 , Counter:  Counter({'no': 19548, 'yes': 9774})\n",
      "f1_none:  [0.86807269 0.58238636]\n",
      "f1_macro:  0.7252295291370061\n",
      "None\n",
      "c:  0.6 , Counter:  Counter({'no': 19548, 'yes': 11728})\n",
      "f1_none:  [0.86442669 0.7115    ]\n",
      "f1_macro:  0.7879633458646615\n",
      "None\n",
      "c:  0.7 , Counter:  Counter({'no': 19548, 'yes': 13683})\n",
      "f1_none:  [0.84625588 0.74505099]\n",
      "f1_macro:  0.7956534341268728\n",
      "None\n",
      "c:  0.8 , Counter:  Counter({'no': 19548, 'yes': 15638})\n",
      "f1_none:  [0.8389662  0.78500332]\n",
      "f1_macro:  0.8119847603166667\n",
      "None\n",
      "c:  0.9 , Counter:  Counter({'no': 19548, 'yes': 17593})\n",
      "f1_none:  [0.83949367 0.81776373]\n",
      "f1_macro:  0.8286286980472346\n",
      "None\n",
      "c:  1 , Counter:  Counter({'no': 19548, 'yes': 19548})\n",
      "f1_none:  [0.82682002 0.83414695]\n",
      "f1_macro:  0.8304834877927088\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for c in [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    print(fit_RF_model(market_all,market_pre['subscribe'],c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccd8e4",
   "metadata": {},
   "source": [
    "### use SMOTE(sample_strategy = 0.9) for RandomForest model also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fb8a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the procedures again\n",
    "X = market_all\n",
    "y = market_pre['subscribe']\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.9)\n",
    "X, y = over.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b78976",
   "metadata": {},
   "source": [
    "#### RansomForest hyperparameter tuning: <br> https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55574697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [0.88558293 0.8912273  0.89248817 0.89276248 0.91365576 0.92097947\n",
      " 0.92235298 0.92333905 0.91527732 0.92499793 0.92782236 0.92810756], using {'max_depth': 32, 'n_estimators': 256}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216159</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.059863</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 8}</td>\n",
       "      <td>0.877571</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.882191</td>\n",
       "      <td>0.885821</td>\n",
       "      <td>0.893697</td>\n",
       "      <td>0.885583</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.691642</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.075978</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 32}</td>\n",
       "      <td>0.887117</td>\n",
       "      <td>0.894543</td>\n",
       "      <td>0.891430</td>\n",
       "      <td>0.889230</td>\n",
       "      <td>0.893816</td>\n",
       "      <td>0.891227</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.289503</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.098651</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 64}</td>\n",
       "      <td>0.889791</td>\n",
       "      <td>0.892651</td>\n",
       "      <td>0.891739</td>\n",
       "      <td>0.893611</td>\n",
       "      <td>0.894649</td>\n",
       "      <td>0.892488</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.069083</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.238732</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 256}</td>\n",
       "      <td>0.887969</td>\n",
       "      <td>0.895149</td>\n",
       "      <td>0.892249</td>\n",
       "      <td>0.893459</td>\n",
       "      <td>0.894986</td>\n",
       "      <td>0.892762</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.316689</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 8}</td>\n",
       "      <td>0.910051</td>\n",
       "      <td>0.908717</td>\n",
       "      <td>0.911333</td>\n",
       "      <td>0.922235</td>\n",
       "      <td>0.915943</td>\n",
       "      <td>0.913656</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.083805</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 32}</td>\n",
       "      <td>0.915514</td>\n",
       "      <td>0.914976</td>\n",
       "      <td>0.923205</td>\n",
       "      <td>0.929673</td>\n",
       "      <td>0.921529</td>\n",
       "      <td>0.920979</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.091027</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.128458</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 64}</td>\n",
       "      <td>0.916683</td>\n",
       "      <td>0.916992</td>\n",
       "      <td>0.921852</td>\n",
       "      <td>0.932193</td>\n",
       "      <td>0.924045</td>\n",
       "      <td>0.922353</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.397560</td>\n",
       "      <td>0.048803</td>\n",
       "      <td>0.366191</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 256}</td>\n",
       "      <td>0.919214</td>\n",
       "      <td>0.919008</td>\n",
       "      <td>0.923381</td>\n",
       "      <td>0.928159</td>\n",
       "      <td>0.926934</td>\n",
       "      <td>0.923339</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.351139</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.060764</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 8}</td>\n",
       "      <td>0.912690</td>\n",
       "      <td>0.914017</td>\n",
       "      <td>0.912804</td>\n",
       "      <td>0.920099</td>\n",
       "      <td>0.916776</td>\n",
       "      <td>0.915277</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.258002</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.096546</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 32}</td>\n",
       "      <td>0.918947</td>\n",
       "      <td>0.921909</td>\n",
       "      <td>0.924934</td>\n",
       "      <td>0.930043</td>\n",
       "      <td>0.929156</td>\n",
       "      <td>0.924998</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.464462</td>\n",
       "      <td>0.034958</td>\n",
       "      <td>0.138362</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 64}</td>\n",
       "      <td>0.922488</td>\n",
       "      <td>0.923791</td>\n",
       "      <td>0.927803</td>\n",
       "      <td>0.934660</td>\n",
       "      <td>0.930369</td>\n",
       "      <td>0.927822</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.718519</td>\n",
       "      <td>0.078179</td>\n",
       "      <td>0.409814</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 256}</td>\n",
       "      <td>0.923517</td>\n",
       "      <td>0.921446</td>\n",
       "      <td>0.930534</td>\n",
       "      <td>0.934490</td>\n",
       "      <td>0.930552</td>\n",
       "      <td>0.928108</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.216159      0.009166         0.059863        0.003532   \n",
       "1        0.691642      0.008222         0.075978        0.002632   \n",
       "2        1.289503      0.009183         0.098651        0.002796   \n",
       "3        5.069083      0.045680         0.238732        0.007952   \n",
       "4        0.316689      0.015151         0.063727        0.001470   \n",
       "5        1.083805      0.007205         0.093154        0.003608   \n",
       "6        2.091027      0.010207         0.128458        0.002260   \n",
       "7        8.397560      0.048803         0.366191        0.011149   \n",
       "8        0.351139      0.007809         0.060764        0.000722   \n",
       "9        1.258002      0.006826         0.096546        0.002945   \n",
       "10       2.464462      0.034958         0.138362        0.002090   \n",
       "11       9.718519      0.078179         0.409814        0.005682   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "0                8                  8     {'max_depth': 8, 'n_estimators': 8}   \n",
       "1                8                 32    {'max_depth': 8, 'n_estimators': 32}   \n",
       "2                8                 64    {'max_depth': 8, 'n_estimators': 64}   \n",
       "3                8                256   {'max_depth': 8, 'n_estimators': 256}   \n",
       "4               16                  8    {'max_depth': 16, 'n_estimators': 8}   \n",
       "5               16                 32   {'max_depth': 16, 'n_estimators': 32}   \n",
       "6               16                 64   {'max_depth': 16, 'n_estimators': 64}   \n",
       "7               16                256  {'max_depth': 16, 'n_estimators': 256}   \n",
       "8               32                  8    {'max_depth': 32, 'n_estimators': 8}   \n",
       "9               32                 32   {'max_depth': 32, 'n_estimators': 32}   \n",
       "10              32                 64   {'max_depth': 32, 'n_estimators': 64}   \n",
       "11              32                256  {'max_depth': 32, 'n_estimators': 256}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.877571           0.888635           0.882191   \n",
       "1            0.887117           0.894543           0.891430   \n",
       "2            0.889791           0.892651           0.891739   \n",
       "3            0.887969           0.895149           0.892249   \n",
       "4            0.910051           0.908717           0.911333   \n",
       "5            0.915514           0.914976           0.923205   \n",
       "6            0.916683           0.916992           0.921852   \n",
       "7            0.919214           0.919008           0.923381   \n",
       "8            0.912690           0.914017           0.912804   \n",
       "9            0.918947           0.921909           0.924934   \n",
       "10           0.922488           0.923791           0.927803   \n",
       "11           0.923517           0.921446           0.930534   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.885821           0.893697         0.885583        0.005494   \n",
       "1            0.889230           0.893816         0.891227        0.002779   \n",
       "2            0.893611           0.894649         0.892488        0.001661   \n",
       "3            0.893459           0.894986         0.892762        0.002622   \n",
       "4            0.922235           0.915943         0.913656        0.004932   \n",
       "5            0.929673           0.921529         0.920979        0.005417   \n",
       "6            0.932193           0.924045         0.922353        0.005672   \n",
       "7            0.928159           0.926934         0.923339        0.003793   \n",
       "8            0.920099           0.916776         0.915277        0.002825   \n",
       "9            0.930043           0.929156         0.924998        0.004217   \n",
       "10           0.934660           0.930369         0.927822        0.004426   \n",
       "11           0.934490           0.930552         0.928108        0.004859   \n",
       "\n",
       "    rank_test_score  \n",
       "0                12  \n",
       "1                11  \n",
       "2                10  \n",
       "3                 9  \n",
       "4                 8  \n",
       "5                 6  \n",
       "6                 5  \n",
       "7                 4  \n",
       "8                 7  \n",
       "9                 3  \n",
       "10                2  \n",
       "11                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching for better hyperparameters\n",
    "# Define Parameters\n",
    "max_depth=[8, 16, 32]\n",
    "n_estimators = [8, 32, 64, 256]\n",
    "param_grid = {'max_depth': max_depth, \n",
    "              'n_estimators': n_estimators}\n",
    "\n",
    "# Build the grid search\n",
    "dfrst = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state = 1)\n",
    "grid = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 5, scoring = 'f1_macro')\n",
    "grid_results = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca6daf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro_grid:  0.9256627992626503\n",
      "[[3725  203]\n",
      " [ 346 3155]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the best decision forest after gridsearchCV\n",
    "best_clf = grid_results.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Print F_macro value after gridsearch\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print('f1_macro_grid: ', f1_macro)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "# Create heatmap from the confusion matrix\n",
    "%matplotlib inline\n",
    "class_names=[False, True] # name  of classes\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = [0.5, 1.5]\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "839b3686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=1, scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try RandomSearchCV using more hyper parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=1, n_jobs = -1, scoring = 'f1_macro')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1dc0091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3950045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro_random:  0.9269637105912469\n",
      "[[3747  181]\n",
      " [ 358 3143]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the best decision forest after randomsearch\n",
    "best_clf = rf_random.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "#f1_macro\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print('f1_macro_random: ', f1_macro)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45678132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create heatmap from the confusion matrix\n",
    "%matplotlib inline\n",
    "class_names=[False, True] # name  of classes\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap='BuPu', fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion Matrix after RandomSearch')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = [0.5, 1.5]\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56693c",
   "metadata": {},
   "source": [
    "## Use hyperparameters picked by RandomSearchCV based on a slightly better F1_macro score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73faf52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
