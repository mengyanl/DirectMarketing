{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79076498",
   "metadata": {},
   "source": [
    "# # SpringBoard Capstone2: Direct Marketing\n",
    "## Unit16: Pre-processing and Training Data Development \n",
    "> Data from Kaggle.com: https://www.kaggle.com/c/bankdirectmarketing/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2c01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e6db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "# check version number\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29da71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d35032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age           job   marital            education  default housing  \\\n",
      "RecordID                                                                      \n",
      "13783      49        admin.  divorced  professional.course       no     yes   \n",
      "23986      52      services   married          high.school  unknown     yes   \n",
      "20663      46   blue-collar  divorced             basic.9y       no      no   \n",
      "13958      26  entrepreneur    single          high.school      yes     yes   \n",
      "28184      47        admin.    single    university.degree       no      no   \n",
      "\n",
      "         loan   contact month day_of_week  ...  campaign  pdays  previous  \\\n",
      "RecordID                                   ...                              \n",
      "13783     yes  cellular   aug         mon  ...         1    115         2   \n",
      "23986      no  cellular   may         mon  ...         1    402         2   \n",
      "20663      no  cellular   apr         wed  ...         1    999         1   \n",
      "13958     yes  cellular   aug         fri  ...        28    999         0   \n",
      "28184      no  cellular   nov         tue  ...         1    252         4   \n",
      "\n",
      "             poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "RecordID                                                                       \n",
      "13783         failure          1.4       92.479703     -35.498996   0.705058   \n",
      "23986     nonexistent         -1.8       93.439161     -39.331320   4.245479   \n",
      "20663         failure         -1.8       93.075000     -47.100000   1.445000   \n",
      "13958     nonexistent          1.4       93.444000     -36.100000   4.967000   \n",
      "28184         success         -3.4       94.352376     -33.073620   1.208702   \n",
      "\n",
      "          nr.employed  subscribe  \n",
      "RecordID                          \n",
      "13783     4990.198481         no  \n",
      "23986     5144.563621        yes  \n",
      "20663     5099.100000         no  \n",
      "13958     5228.100000        yes  \n",
      "28184     5025.420036         no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "market_pre = pd.read_csv('Market_explored.csv', index_col = 0)\n",
    "print(market_pre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541de751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
       "RecordID                                                                     \n",
       "13783                   0                 0              0               0   \n",
       "23986                   0                 0              0               0   \n",
       "20663                   1                 0              0               0   \n",
       "13958                   0                 1              0               0   \n",
       "28184                   0                 0              0               0   \n",
       "\n",
       "          job_retired  job_self-employed  job_services  job_student  \\\n",
       "RecordID                                                              \n",
       "13783               0                  0             0            0   \n",
       "23986               0                  0             1            0   \n",
       "20663               0                  0             0            0   \n",
       "13958               0                  0             0            0   \n",
       "28184               0                  0             0            0   \n",
       "\n",
       "          job_technician  job_unemployed  ...  month_may  month_nov  \\\n",
       "RecordID                                  ...                         \n",
       "13783                  0               0  ...          0          0   \n",
       "23986                  0               0  ...          1          0   \n",
       "20663                  0               0  ...          0          0   \n",
       "13958                  0               0  ...          0          0   \n",
       "28184                  0               0  ...          0          1   \n",
       "\n",
       "          month_oct  month_sep  day_of_week_mon  day_of_week_thu  \\\n",
       "RecordID                                                           \n",
       "13783             0          0                1                0   \n",
       "23986             0          0                1                0   \n",
       "20663             0          0                0                0   \n",
       "13958             0          0                0                0   \n",
       "28184             0          0                0                0   \n",
       "\n",
       "          day_of_week_tue  day_of_week_wed  poutcome_nonexistent  \\\n",
       "RecordID                                                           \n",
       "13783                   0                0                     0   \n",
       "23986                   0                0                     1   \n",
       "20663                   0                1                     0   \n",
       "13958                   0                0                     1   \n",
       "28184                   1                0                     0   \n",
       "\n",
       "          poutcome_success  \n",
       "RecordID                    \n",
       "13783                    0  \n",
       "23986                    0  \n",
       "20663                    0  \n",
       "13958                    0  \n",
       "28184                    1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = market_pre[['job', 'marital', 'education', 'default', 'housing', \\\n",
    " 'loan', 'contact', 'month', 'day_of_week', 'poutcome']]\n",
    "market_cat = pd.get_dummies(cat,drop_first = True)\n",
    "print(market_cat.shape)\n",
    "market_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afc4e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>4457</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>92.479703</td>\n",
       "      <td>-35.498996</td>\n",
       "      <td>0.705058</td>\n",
       "      <td>4990.198481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4797</td>\n",
       "      <td>1</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.439161</td>\n",
       "      <td>-39.331320</td>\n",
       "      <td>4.245479</td>\n",
       "      <td>5144.563621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-47.100000</td>\n",
       "      <td>1.445000</td>\n",
       "      <td>5099.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>376</td>\n",
       "      <td>28</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444000</td>\n",
       "      <td>-36.100000</td>\n",
       "      <td>4.967000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>3033</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>94.352376</td>\n",
       "      <td>-33.073620</td>\n",
       "      <td>1.208702</td>\n",
       "      <td>5025.420036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
       "RecordID                                                                     \n",
       "13783                   0                 0              0               0   \n",
       "23986                   0                 0              0               0   \n",
       "20663                   1                 0              0               0   \n",
       "13958                   0                 1              0               0   \n",
       "28184                   0                 0              0               0   \n",
       "\n",
       "          job_retired  job_self-employed  job_services  job_student  \\\n",
       "RecordID                                                              \n",
       "13783               0                  0             0            0   \n",
       "23986               0                  0             1            0   \n",
       "20663               0                  0             0            0   \n",
       "13958               0                  0             0            0   \n",
       "28184               0                  0             0            0   \n",
       "\n",
       "          job_technician  job_unemployed  ...  age  duration  campaign  pdays  \\\n",
       "RecordID                                  ...                                   \n",
       "13783                  0               0  ...   49      4457         1    115   \n",
       "23986                  0               0  ...   52      4797         1    402   \n",
       "20663                  0               0  ...   46       169         1    999   \n",
       "13958                  0               0  ...   26       376        28    999   \n",
       "28184                  0               0  ...   47      3033         1    252   \n",
       "\n",
       "          previous  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "RecordID                                                                     \n",
       "13783            2           1.4       92.479703     -35.498996   0.705058   \n",
       "23986            2          -1.8       93.439161     -39.331320   4.245479   \n",
       "20663            1          -1.8       93.075000     -47.100000   1.445000   \n",
       "13958            0           1.4       93.444000     -36.100000   4.967000   \n",
       "28184            4          -3.4       94.352376     -33.073620   1.208702   \n",
       "\n",
       "          nr.employed  \n",
       "RecordID               \n",
       "13783     4990.198481  \n",
       "23986     5144.563621  \n",
       "20663     5099.100000  \n",
       "13958     5228.100000  \n",
       "28184     5025.420036  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', \\\n",
    "             'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "market_num = market_pre[num]\n",
    "market_all = market_cat.join(market_num)\n",
    "market_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e53e0e",
   "metadata": {},
   "source": [
    "#### SMOTE\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccdbc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logreg_model(X,y,c):\n",
    "    X = market_all\n",
    "    y = market_pre['subscribe']\n",
    "    over = SMOTE(sampling_strategy=c)\n",
    "    X, y = over.fit_resample(X, y)\n",
    "    counter = Counter(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled=scaler.transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return [c, counter, f1_score(y_test, y_pred, average=None), f1_score(y_test, y_pred, average='macro')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3454ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, Counter({'no': 19548, 'yes': 5864}), array([0.87609571, 0.39327146]), 0.6346835868167724]\n",
      "[0.4, Counter({'no': 19548, 'yes': 7819}), array([0.85926275, 0.51363451]), 0.6864486312136765]\n",
      "[0.5, Counter({'no': 19548, 'yes': 9774}), array([0.83815097, 0.56577708]), 0.7019640227698407]\n",
      "[0.6, Counter({'no': 19548, 'yes': 11728}), array([0.8155061 , 0.62879153]), 0.7221488140890158]\n",
      "[0.7, Counter({'no': 19548, 'yes': 13683}), array([0.79555718, 0.67163301]), 0.7335950980478718]\n",
      "[0.8, Counter({'no': 19548, 'yes': 15638}), array([0.74650954, 0.68431967]), 0.7154146054633596]\n",
      "[0.9, Counter({'no': 19548, 'yes': 17593}), array([0.76298538, 0.72855905]), 0.7457722142688742]\n",
      "[1, Counter({'no': 19548, 'yes': 19548}), array([0.74242618, 0.74222848]), 0.7423273278063649]\n"
     ]
    }
   ],
   "source": [
    "for c in [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    print(fit_logreg_model(X,y,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305d733",
   "metadata": {},
   "source": [
    "### use sampling_strategy = 0.9 for SMOTE( ) over sampling for category 1, f1_macro = 0.746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81ce8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build scaler based on training data and apply it to test data to then also scale the test data\n",
    "# import sklearn.preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_scaled=scaler.transform(X_train)\n",
    "# X_test_scaled=scaler.transform(X_test)\n",
    "# X_train_scaled[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1e5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "# X_train_scaled=scaler.transform(X_train)\n",
    "# X_test_scaled=scaler.transform(X_test)\n",
    "# X_train_scaled[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566183de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(X_train[num])\n",
    "# X_train_scaled=scaler.transform(X_train[num])\n",
    "# X_test_scaled=scaler.transform(X_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc20c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the logistic regression classifier: logreg\n",
    "# logreg = LogisticRegression()\n",
    "# # Fit it to the training data\n",
    "# logreg.fit(X_train,y_train)\n",
    "# y_pred = logreg.predict(X_test)\n",
    "# # Compute and print the confusion matrix and classification report\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf23e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = market_all\n",
    "y = market_pre['subscribe']\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.9)\n",
    "X, y = over.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c55d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 62.10169418915616, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Average f1_macro: 0.7596970413364377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-4, 4, 30)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5, scoring='f1_macro')\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Average f1_macro: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "547bb071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_no_average:  [0.93073542 0.        ]\n",
      "f1_macro:  0.4653677082095759\n"
     ]
    }
   ],
   "source": [
    "X = market_all\n",
    "y = market_pre['subscribe']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "X_train_scaled[0:1]\n",
    "\n",
    "RF = RandomForestClassifier(max_depth=3, random_state = 1)\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "print('f1_no_average: ', f1_score(y_test, y_pred, average=None))\n",
    "print('f1_macro: ', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a180540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_RF_model(X,y,c):\n",
    "    X = market_all\n",
    "    y = market_pre['subscribe']\n",
    "    over = SMOTE(sampling_strategy=c)\n",
    "    X, y = over.fit_resample(X, y)\n",
    "    counter = Counter(y)\n",
    "    print('c: ', c, ', Counter: ', counter)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled=scaler.transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "    X_train_scaled[0:1]\n",
    "\n",
    "    RF = RandomForestClassifier(max_depth=3, random_state = 1)\n",
    "    RF.fit(X_train,y_train)\n",
    "    y_pred = RF.predict(X_test)\n",
    " \n",
    "    print('f1_none: ', f1_score(y_test, y_pred, average=None))\n",
    "    print('f1_macro: ', f1_score(y_test, y_pred, average='macro')) \n",
    "    return[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "387a7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  0.3 , Counter:  Counter({'no': 19548, 'yes': 5864})\n",
      "f1_none:  [0.8772246  0.15372671]\n",
      "f1_macro:  0.5154756541048499\n",
      "[]\n",
      "c:  0.4 , Counter:  Counter({'no': 19548, 'yes': 7819})\n",
      "f1_none:  [0.8575804  0.27906977]\n",
      "f1_macro:  0.5683250828020942\n",
      "[]\n",
      "c:  0.5 , Counter:  Counter({'no': 19548, 'yes': 9774})\n",
      "f1_none:  [0.87147548 0.60848568]\n",
      "f1_macro:  0.7399805844045028\n",
      "[]\n",
      "c:  0.6 , Counter:  Counter({'no': 19548, 'yes': 11728})\n",
      "f1_none:  [0.86319755 0.71080139]\n",
      "f1_macro:  0.7869994724704218\n",
      "[]\n",
      "c:  0.7 , Counter:  Counter({'no': 19548, 'yes': 13683})\n",
      "f1_none:  [0.85623859 0.76747391]\n",
      "f1_macro:  0.8118562500681563\n",
      "[]\n",
      "c:  0.8 , Counter:  Counter({'no': 19548, 'yes': 15638})\n",
      "f1_none:  [0.84617296 0.79462508]\n",
      "f1_macro:  0.8203990225864455\n",
      "[]\n",
      "c:  0.9 , Counter:  Counter({'no': 19548, 'yes': 17593})\n",
      "f1_none:  [0.83700887 0.81544202]\n",
      "f1_macro:  0.8262254463278809\n",
      "[]\n",
      "c:  1 , Counter:  Counter({'no': 19548, 'yes': 19548})\n",
      "f1_none:  [0.82818004 0.83485893]\n",
      "f1_macro:  0.8315194866541111\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for c in [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    print(fit_RF_model(X,y,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccd8e4",
   "metadata": {},
   "source": [
    "### use SMOTE(sample_strategy = 0.9) for RandomForest model also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1fb8a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the procedures again\n",
    "X = market_all\n",
    "y = market_pre['subscribe']\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.9)\n",
    "X, y = over.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55574697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [0.88599583 0.88958966 0.89136782 0.89267038 0.91283978 0.91837906\n",
      " 0.9215375  0.92326765 0.91554422 0.92530404 0.92619598 0.92868443], using {'max_depth': 32, 'n_estimators': 256}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.302984</td>\n",
       "      <td>0.063742</td>\n",
       "      <td>0.096886</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 8}</td>\n",
       "      <td>0.879243</td>\n",
       "      <td>0.883009</td>\n",
       "      <td>0.889929</td>\n",
       "      <td>0.891314</td>\n",
       "      <td>0.886485</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.166684</td>\n",
       "      <td>0.341932</td>\n",
       "      <td>0.145112</td>\n",
       "      <td>0.072132</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 32}</td>\n",
       "      <td>0.882057</td>\n",
       "      <td>0.885866</td>\n",
       "      <td>0.890380</td>\n",
       "      <td>0.894640</td>\n",
       "      <td>0.895005</td>\n",
       "      <td>0.889590</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.586052</td>\n",
       "      <td>0.194181</td>\n",
       "      <td>0.125949</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 64}</td>\n",
       "      <td>0.885066</td>\n",
       "      <td>0.890914</td>\n",
       "      <td>0.893258</td>\n",
       "      <td>0.894978</td>\n",
       "      <td>0.892623</td>\n",
       "      <td>0.891368</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.483046</td>\n",
       "      <td>0.163779</td>\n",
       "      <td>0.273093</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 256}</td>\n",
       "      <td>0.887783</td>\n",
       "      <td>0.890590</td>\n",
       "      <td>0.893295</td>\n",
       "      <td>0.897370</td>\n",
       "      <td>0.894315</td>\n",
       "      <td>0.892670</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.331990</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 8}</td>\n",
       "      <td>0.910817</td>\n",
       "      <td>0.903825</td>\n",
       "      <td>0.918114</td>\n",
       "      <td>0.919194</td>\n",
       "      <td>0.912249</td>\n",
       "      <td>0.912840</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.125955</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>0.093180</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 32}</td>\n",
       "      <td>0.911988</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.924607</td>\n",
       "      <td>0.923051</td>\n",
       "      <td>0.918379</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.252558</td>\n",
       "      <td>0.048553</td>\n",
       "      <td>0.133646</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 64}</td>\n",
       "      <td>0.917681</td>\n",
       "      <td>0.916138</td>\n",
       "      <td>0.923032</td>\n",
       "      <td>0.927475</td>\n",
       "      <td>0.923361</td>\n",
       "      <td>0.921538</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.873225</td>\n",
       "      <td>0.254568</td>\n",
       "      <td>0.377858</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 16, 'n_estimators': 256}</td>\n",
       "      <td>0.919711</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.924385</td>\n",
       "      <td>0.926800</td>\n",
       "      <td>0.927109</td>\n",
       "      <td>0.923268</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.370088</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 8}</td>\n",
       "      <td>0.911147</td>\n",
       "      <td>0.910747</td>\n",
       "      <td>0.916850</td>\n",
       "      <td>0.921143</td>\n",
       "      <td>0.917835</td>\n",
       "      <td>0.915544</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.298856</td>\n",
       "      <td>0.029749</td>\n",
       "      <td>0.100165</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 32}</td>\n",
       "      <td>0.918589</td>\n",
       "      <td>0.923934</td>\n",
       "      <td>0.923418</td>\n",
       "      <td>0.930734</td>\n",
       "      <td>0.929845</td>\n",
       "      <td>0.925304</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.626291</td>\n",
       "      <td>0.092680</td>\n",
       "      <td>0.152083</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 64}</td>\n",
       "      <td>0.920124</td>\n",
       "      <td>0.922961</td>\n",
       "      <td>0.926782</td>\n",
       "      <td>0.931265</td>\n",
       "      <td>0.929848</td>\n",
       "      <td>0.926196</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.383539</td>\n",
       "      <td>0.204861</td>\n",
       "      <td>0.483507</td>\n",
       "      <td>0.050768</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 32, 'n_estimators': 256}</td>\n",
       "      <td>0.923866</td>\n",
       "      <td>0.923486</td>\n",
       "      <td>0.928673</td>\n",
       "      <td>0.936346</td>\n",
       "      <td>0.931051</td>\n",
       "      <td>0.928684</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.302984      0.063742         0.096886        0.023003   \n",
       "1        1.166684      0.341932         0.145112        0.072132   \n",
       "2        1.586052      0.194181         0.125949        0.018732   \n",
       "3        5.483046      0.163779         0.273093        0.025518   \n",
       "4        0.331990      0.010627         0.064215        0.003372   \n",
       "5        1.125955      0.024464         0.093180        0.002270   \n",
       "6        2.252558      0.048553         0.133646        0.003177   \n",
       "7        8.873225      0.254568         0.377858        0.009776   \n",
       "8        0.370088      0.004851         0.066334        0.003181   \n",
       "9        1.298856      0.029749         0.100165        0.002046   \n",
       "10       2.626291      0.092680         0.152083        0.004046   \n",
       "11      10.383539      0.204861         0.483507        0.050768   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "0                8                  8     {'max_depth': 8, 'n_estimators': 8}   \n",
       "1                8                 32    {'max_depth': 8, 'n_estimators': 32}   \n",
       "2                8                 64    {'max_depth': 8, 'n_estimators': 64}   \n",
       "3                8                256   {'max_depth': 8, 'n_estimators': 256}   \n",
       "4               16                  8    {'max_depth': 16, 'n_estimators': 8}   \n",
       "5               16                 32   {'max_depth': 16, 'n_estimators': 32}   \n",
       "6               16                 64   {'max_depth': 16, 'n_estimators': 64}   \n",
       "7               16                256  {'max_depth': 16, 'n_estimators': 256}   \n",
       "8               32                  8    {'max_depth': 32, 'n_estimators': 8}   \n",
       "9               32                 32   {'max_depth': 32, 'n_estimators': 32}   \n",
       "10              32                 64   {'max_depth': 32, 'n_estimators': 64}   \n",
       "11              32                256  {'max_depth': 32, 'n_estimators': 256}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.879243           0.883009           0.889929   \n",
       "1            0.882057           0.885866           0.890380   \n",
       "2            0.885066           0.890914           0.893258   \n",
       "3            0.887783           0.890590           0.893295   \n",
       "4            0.910817           0.903825           0.918114   \n",
       "5            0.911988           0.913444           0.918805   \n",
       "6            0.917681           0.916138           0.923032   \n",
       "7            0.919711           0.918333           0.924385   \n",
       "8            0.911147           0.910747           0.916850   \n",
       "9            0.918589           0.923934           0.923418   \n",
       "10           0.920124           0.922961           0.926782   \n",
       "11           0.923866           0.923486           0.928673   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.891314           0.886485         0.885996        0.004439   \n",
       "1            0.894640           0.895005         0.889590        0.005021   \n",
       "2            0.894978           0.892623         0.891368        0.003409   \n",
       "3            0.897370           0.894315         0.892670        0.003268   \n",
       "4            0.919194           0.912249         0.912840        0.005548   \n",
       "5            0.924607           0.923051         0.918379        0.005020   \n",
       "6            0.927475           0.923361         0.921538        0.004119   \n",
       "7            0.926800           0.927109         0.923268        0.003619   \n",
       "8            0.921143           0.917835         0.915544        0.004016   \n",
       "9            0.930734           0.929845         0.925304        0.004486   \n",
       "10           0.931265           0.929848         0.926196        0.004164   \n",
       "11           0.936346           0.931051         0.928684        0.004786   \n",
       "\n",
       "    rank_test_score  \n",
       "0                12  \n",
       "1                11  \n",
       "2                10  \n",
       "3                 9  \n",
       "4                 8  \n",
       "5                 6  \n",
       "6                 5  \n",
       "7                 4  \n",
       "8                 7  \n",
       "9                 3  \n",
       "10                2  \n",
       "11                1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Parameters\n",
    "max_depth=[8, 16, 32]\n",
    "n_estimators = [8, 32, 64, 256]\n",
    "param_grid = {'max_depth': max_depth, \n",
    "              'n_estimators': n_estimators}\n",
    "\n",
    "# Build the grid search\n",
    "dfrst = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state = 1)\n",
    "grid = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 5, scoring = 'f1_macro')\n",
    "grid_results = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ca6daf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3722  206]\n",
      " [ 335 3166]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the best decision forest \n",
    "best_clf = grid_results.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "# Create heatmap from the confusion matrix\n",
    "%matplotlib inline\n",
    "class_names=[False, True] # name  of classes\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = [0.5, 1.5]\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb1462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
